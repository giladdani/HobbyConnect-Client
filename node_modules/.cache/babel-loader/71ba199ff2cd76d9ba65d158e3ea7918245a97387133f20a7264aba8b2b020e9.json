{"ast":null,"code":"\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.OrderedBulkOperation = void 0;\nconst BSON = require(\"../bson\");\nconst common_1 = require(\"./common\");\nconst error_1 = require(\"../error\");\n/** @public */\nclass OrderedBulkOperation extends common_1.BulkOperationBase {\n  constructor(collection, options) {\n    super(collection, options, true);\n  }\n  addToOperationsList(batchType, document) {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    });\n    // Throw error if the doc is bigger than the max BSON size\n    if (bsonSize >= this.s.maxBsonObjectSize)\n      // TODO(NODE-3483): Change this to MongoBSONError\n      throw new error_1.MongoInvalidArgumentError(`Document is larger than the maximum size ${this.s.maxBsonObjectSize}`);\n    // Create a new batch object if we don't have a current one\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n    }\n    const maxKeySize = this.s.maxKeySize;\n    // Check if we need to create a new batch\n    if (\n    // New batch if we exceed the max batch op size\n    this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n    // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n    // since we can't sent an empty batch\n    this.s.currentBatchSize > 0 && this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes ||\n    // New batch if the new op does not have the same op type as the current batch\n    this.s.currentBatch.batchType !== batchType) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch);\n      // Create a new batch\n      this.s.currentBatch = new common_1.Batch(batchType, this.s.currentIndex);\n      // Reset the current size trackers\n      this.s.currentBatchSize = 0;\n      this.s.currentBatchSizeBytes = 0;\n    }\n    if (batchType === common_1.BatchType.INSERT) {\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.currentIndex,\n        _id: document._id\n      });\n    }\n    // We have an array of documents\n    if (Array.isArray(document)) {\n      throw new error_1.MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatchSize += 1;\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n    this.s.currentIndex += 1;\n    return this;\n  }\n}\nexports.OrderedBulkOperation = OrderedBulkOperation;","map":{"version":3,"mappings":";;;;;;AAAA;AACA;AAKA;AAEA;AACA,MAAaA,oBAAqB,SAAQC,0BAAiB;EACzDC,YAAYC,UAAsB,EAAEC,OAAyB;IAC3D,KAAK,CAACD,UAAU,EAAEC,OAAO,EAAE,IAAI,CAAC;EAClC;EAEAC,mBAAmB,CACjBC,SAAoB,EACpBC,QAAsD;IAEtD;IACA,MAAMC,QAAQ,GAAGC,IAAI,CAACC,mBAAmB,CAACH,QAAQ,EAAE;MAClDI,SAAS,EAAE,KAAK;MAChB;MACA;MACAC,eAAe,EAAE;KACX,CAAC;IAET;IACA,IAAIJ,QAAQ,IAAI,IAAI,CAACK,CAAC,CAACC,iBAAiB;MACtC;MACA,MAAM,IAAIC,iCAAyB,CACjC,4CAA4C,IAAI,CAACF,CAAC,CAACC,iBAAiB,EAAE,CACvE;IAEH;IACA,IAAI,IAAI,CAACD,CAAC,CAACG,YAAY,IAAI,IAAI,EAAE;MAC/B,IAAI,CAACH,CAAC,CAACG,YAAY,GAAG,IAAIf,cAAK,CAACK,SAAS,EAAE,IAAI,CAACO,CAAC,CAACI,YAAY,CAAC;;IAGjE,MAAMC,UAAU,GAAG,IAAI,CAACL,CAAC,CAACK,UAAU;IAEpC;IACA;IACE;IACA,IAAI,CAACL,CAAC,CAACM,gBAAgB,GAAG,CAAC,IAAI,IAAI,CAACN,CAAC,CAACO,iBAAiB;IACvD;IACA;IACC,IAAI,CAACP,CAAC,CAACM,gBAAgB,GAAG,CAAC,IAC1B,IAAI,CAACN,CAAC,CAACQ,qBAAqB,GAAGH,UAAU,GAAGV,QAAQ,IAAI,IAAI,CAACK,CAAC,CAACS,iBAAkB;IACnF;IACA,IAAI,CAACT,CAAC,CAACG,YAAY,CAACV,SAAS,KAAKA,SAAS,EAC3C;MACA;MACA,IAAI,CAACO,CAAC,CAACU,OAAO,CAACC,IAAI,CAAC,IAAI,CAACX,CAAC,CAACG,YAAY,CAAC;MAExC;MACA,IAAI,CAACH,CAAC,CAACG,YAAY,GAAG,IAAIf,cAAK,CAACK,SAAS,EAAE,IAAI,CAACO,CAAC,CAACI,YAAY,CAAC;MAE/D;MACA,IAAI,CAACJ,CAAC,CAACM,gBAAgB,GAAG,CAAC;MAC3B,IAAI,CAACN,CAAC,CAACQ,qBAAqB,GAAG,CAAC;;IAGlC,IAAIf,SAAS,KAAKL,kBAAS,CAACwB,MAAM,EAAE;MAClC,IAAI,CAACZ,CAAC,CAACa,UAAU,CAACC,WAAW,CAACH,IAAI,CAAC;QACjCI,KAAK,EAAE,IAAI,CAACf,CAAC,CAACI,YAAY;QAC1BY,GAAG,EAAGtB,QAAqB,CAACsB;OAC7B,CAAC;;IAGJ;IACA,IAAIC,KAAK,CAACC,OAAO,CAACxB,QAAQ,CAAC,EAAE;MAC3B,MAAM,IAAIQ,iCAAyB,CAAC,wCAAwC,CAAC;;IAG/E,IAAI,CAACF,CAAC,CAACG,YAAY,CAACgB,eAAe,CAACR,IAAI,CAAC,IAAI,CAACX,CAAC,CAACI,YAAY,CAAC;IAC7D,IAAI,CAACJ,CAAC,CAACG,YAAY,CAACiB,UAAU,CAACT,IAAI,CAACjB,QAAQ,CAAC;IAC7C,IAAI,CAACM,CAAC,CAACM,gBAAgB,IAAI,CAAC;IAC5B,IAAI,CAACN,CAAC,CAACQ,qBAAqB,IAAIH,UAAU,GAAGV,QAAQ;IACrD,IAAI,CAACK,CAAC,CAACI,YAAY,IAAI,CAAC;IACxB,OAAO,IAAI;EACb;;AAvEFiB","names":["OrderedBulkOperation","common_1","constructor","collection","options","addToOperationsList","batchType","document","bsonSize","BSON","calculateObjectSize","checkKeys","ignoreUndefined","s","maxBsonObjectSize","error_1","currentBatch","currentIndex","maxKeySize","currentBatchSize","maxWriteBatchSize","currentBatchSizeBytes","maxBatchSizeBytes","batches","push","INSERT","bulkResult","insertedIds","index","_id","Array","isArray","originalIndexes","operations","exports"],"sources":["C:\\Users\\danin\\node_modules\\mongodb\\src\\bulk\\ordered.ts"],"sourcesContent":["import * as BSON from '../bson';\nimport { BulkOperationBase, Batch, BatchType, BulkWriteOptions } from './common';\nimport type { Document } from '../bson';\nimport type { Collection } from '../collection';\nimport type { UpdateStatement } from '../operations/update';\nimport type { DeleteStatement } from '../operations/delete';\nimport { MongoInvalidArgumentError } from '../error';\n\n/** @public */\nexport class OrderedBulkOperation extends BulkOperationBase {\n  constructor(collection: Collection, options: BulkWriteOptions) {\n    super(collection, options, true);\n  }\n\n  addToOperationsList(\n    batchType: BatchType,\n    document: Document | UpdateStatement | DeleteStatement\n  ): this {\n    // Get the bsonSize\n    const bsonSize = BSON.calculateObjectSize(document, {\n      checkKeys: false,\n      // Since we don't know what the user selected for BSON options here,\n      // err on the safe side, and check the size with ignoreUndefined: false.\n      ignoreUndefined: false\n    } as any);\n\n    // Throw error if the doc is bigger than the max BSON size\n    if (bsonSize >= this.s.maxBsonObjectSize)\n      // TODO(NODE-3483): Change this to MongoBSONError\n      throw new MongoInvalidArgumentError(\n        `Document is larger than the maximum size ${this.s.maxBsonObjectSize}`\n      );\n\n    // Create a new batch object if we don't have a current one\n    if (this.s.currentBatch == null) {\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n    }\n\n    const maxKeySize = this.s.maxKeySize;\n\n    // Check if we need to create a new batch\n    if (\n      // New batch if we exceed the max batch op size\n      this.s.currentBatchSize + 1 >= this.s.maxWriteBatchSize ||\n      // New batch if we exceed the maxBatchSizeBytes. Only matters if batch already has a doc,\n      // since we can't sent an empty batch\n      (this.s.currentBatchSize > 0 &&\n        this.s.currentBatchSizeBytes + maxKeySize + bsonSize >= this.s.maxBatchSizeBytes) ||\n      // New batch if the new op does not have the same op type as the current batch\n      this.s.currentBatch.batchType !== batchType\n    ) {\n      // Save the batch to the execution stack\n      this.s.batches.push(this.s.currentBatch);\n\n      // Create a new batch\n      this.s.currentBatch = new Batch(batchType, this.s.currentIndex);\n\n      // Reset the current size trackers\n      this.s.currentBatchSize = 0;\n      this.s.currentBatchSizeBytes = 0;\n    }\n\n    if (batchType === BatchType.INSERT) {\n      this.s.bulkResult.insertedIds.push({\n        index: this.s.currentIndex,\n        _id: (document as Document)._id\n      });\n    }\n\n    // We have an array of documents\n    if (Array.isArray(document)) {\n      throw new MongoInvalidArgumentError('Operation passed in cannot be an Array');\n    }\n\n    this.s.currentBatch.originalIndexes.push(this.s.currentIndex);\n    this.s.currentBatch.operations.push(document);\n    this.s.currentBatchSize += 1;\n    this.s.currentBatchSizeBytes += maxKeySize + bsonSize;\n    this.s.currentIndex += 1;\n    return this;\n  }\n}\n"]},"metadata":{},"sourceType":"script","externalDependencies":[]}